{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T21:27:03.753963Z",
     "start_time": "2025-02-15T21:27:03.462458Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python -m pip install pandas numpy matplotlib seaborn networkx scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92393dc",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89401dc4ecddf320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T21:28:38.896456Z",
     "start_time": "2025-02-15T21:28:38.413621Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c398de3e70225d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T21:28:40.426630Z",
     "start_time": "2025-02-15T21:28:40.153546Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('lol_ranked_games.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b579bcdddd13c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T22:17:09.778010Z",
     "start_time": "2025-02-15T22:17:09.768092Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total rows:\", df.shape[0])\n",
    "print(\"Total columns:\", df.shape[1])\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52e847854e3353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T21:29:20.948610Z",
     "start_time": "2025-02-15T21:29:20.943140Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Missing Data: \\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2317bbd470266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T22:11:46.637870Z",
     "start_time": "2025-02-15T22:11:46.516483Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff4008f38173ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T21:30:43.491869Z",
     "start_time": "2025-02-15T21:30:41.255559Z"
    }
   },
   "outputs": [],
   "source": [
    "df.hist(bins=30, figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fce33f18818d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T21:33:17.204212Z",
     "start_time": "2025-02-15T21:33:12.387698Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_columns = ['goldDiff', 'expDiff', 'kills', 'deaths', 'assists']\n",
    "sns.pairplot(df[selected_columns])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7b26eff45b2f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T21:34:33.036657Z",
     "start_time": "2025-02-15T21:34:30.509945Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 35))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d0dc79090ea01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T22:17:48.057Z",
     "start_time": "2025-02-15T22:17:46.988601Z"
    }
   },
   "outputs": [],
   "source": [
    "winning_correlation = df.corr()['hasWon'].to_frame().T\n",
    "plt.subplots(figsize=(20, 2))\n",
    "sns.heatmap(winning_correlation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883641192cf7fc0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T22:33:12.383497Z",
     "start_time": "2025-02-15T22:33:12.127766Z"
    }
   },
   "outputs": [],
   "source": [
    "df_f10 = df[df['frame'] == 10]\n",
    "winning_correlation = df_f10.corr()['hasWon'].to_frame().T\n",
    "plt.subplots(figsize=(20, 2))\n",
    "sns.heatmap(winning_correlation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371a698fa615db0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T22:39:02.713297Z",
     "start_time": "2025-02-15T22:39:02.710205Z"
    }
   },
   "outputs": [],
   "source": [
    "high_impact_columns = ['goldDiff', 'expDiff', 'champLevelDiff', 'kills', 'deaths', 'assists', 'isFirstTower', 'isFirstBlood']\n",
    "df_high_impact = df[high_impact_columns]\n",
    "print(df_high_impact.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9803319bf24cc418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T23:51:24.089810Z",
     "start_time": "2025-02-15T23:51:23.705299Z"
    }
   },
   "outputs": [],
   "source": [
    "#DATA SETUP\n",
    "\n",
    "# Filter for frame=10\n",
    "df_frame_10 = df[df['frame'] == 10].copy()\n",
    "\n",
    "# Create derived columns\n",
    "df_frame_10['kda'] = df_frame_10['kills'] + (df_frame_10['assists'] // 2) - df_frame_10['deaths']\n",
    "df_frame_10['wardsDiff'] = df_frame_10['wardsPlaced'] - df_frame_10['wardsLost']\n",
    "\n",
    "drake_columns_killed = ['killedFireDrake', 'killedWaterDrake', 'killedAirDrake', 'killedEarthDrake']\n",
    "drake_columns_lost = ['lostFireDrake', 'lostWaterDrake', 'lostAirDrake', 'lostEarthDrake']\n",
    "df_frame_10['drakeDiff'] = df[drake_columns_killed].sum(axis=1) - df[drake_columns_lost].sum(axis=1)\n",
    "\n",
    "turrets_destroyed = ['destroyedTopOuterTurret', 'destroyedMidOuterTurret', 'destroyedBotOuterTurret']\n",
    "turret_lost = ['lostTopOuterTurret', 'lostMidOuterTurret', 'lostBotOuterTurret']\n",
    "df_frame_10['laneProgression'] = df[turrets_destroyed].sum(axis=1) - df[turret_lost].sum(axis=1)\n",
    "\n",
    "# Discretize data\n",
    "df_frame_10['goldDiff'] = (df_frame_10['goldDiff'] > 0).astype(int)\n",
    "df_frame_10['expDiff'] = (df_frame_10['expDiff'] > 0).astype(int)\n",
    "df_frame_10['wardsDiff'] = (df_frame_10['wardsDiff'] > 0).astype(int)\n",
    "df_frame_10['drakeDiff'] = (df_frame_10['drakeDiff'] > 0).astype(int)\n",
    "df_frame_10['kda'] = (df_frame_10['kda'] > 1).astype(int)\n",
    "df_frame_10['killedRiftHerald'] = (df_frame_10['killedRiftHerald'] > 0).astype(int)\n",
    "df_frame_10['laneProgression'] = (df_frame_10['laneProgression'] > 0).astype(int)\n",
    "\n",
    "# Select relevant columns\n",
    "df_bn = df_frame_10[['hasWon', 'goldDiff', 'expDiff', 'kda', 'wardsDiff', 'isFirstBlood', 'isFirstTower',\n",
    "                     'killedRiftHerald', 'drakeDiff', 'laneProgression']]\n",
    "display(df_bn.head())\n",
    "\n",
    "# Define Bayesian network edges manually based on provided design with separate goldDiff and expDiff\n",
    "edges = [\n",
    "    ('kda', 'goldDiff'),\n",
    "    ('kda', 'expDiff'),\n",
    "    ('isFirstBlood', 'kda'),\n",
    "    ('drakeDiff', 'kda'),\n",
    "    ('wardsDiff', 'drakeDiff'),\n",
    "    ('wardsDiff', 'isFirstBlood'),\n",
    "    ('wardsDiff', 'kda'),\n",
    "    ('isFirstTower', 'laneProgression'),\n",
    "    ('laneProgression', 'hasWon'),\n",
    "    ('killedRiftHerald', 'laneProgression'),\n",
    "    ('killedRiftHerald', 'isFirstTower'),\n",
    "    ('drakeDiff', 'kda'),\n",
    "    ('isFirstTower', 'kda'),\n",
    "    ('goldDiff', 'hasWon'),\n",
    "    ('expDiff', 'hasWon')\n",
    "]\n",
    "\n",
    "# Visualize the network\n",
    "plt.figure(figsize=(12, 8))\n",
    "G = nx.DiGraph(edges)\n",
    "nx.draw(G, with_labels=True, node_size=3000, node_color='lightblue', font_size=15, font_weight='bold')\n",
    "plt.title('Bayesian Network for LoL Data with Separate goldDiff and expDiff Nodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db2038",
   "metadata": {},
   "source": [
    "Bayesian Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba547d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA SPLITTING AND CPTS\n",
    "\n",
    "target = 'hasWon'\n",
    "train_data, test_data = train_test_split(df_bn, test_size=0.25, random_state=42)\n",
    "print(f\"Training Set Size: {len(train_data)}, Testing Set Size: {len(test_data)}\")\n",
    "\n",
    "# Calculating CPTs using Maximum Likelihood Estimation(MLE)\n",
    "P_hasWon_given_gd_ed_lp = train_data.groupby(['goldDiff', 'expDiff', 'laneProgression'])['hasWon'].value_counts(normalize=True).unstack().fillna(0)\n",
    "P_lp_given_ft_rh = train_data.groupby(['isFirstTower', 'killedRiftHerald'])['laneProgression'].value_counts(normalize=True).unstack().fillna(0)\n",
    "P_gd_given_k = train_data.groupby('kda')['goldDiff'].value_counts(normalize=True).unstack().fillna(0)\n",
    "P_ed_given_k = train_data.groupby('kda')['expDiff'].value_counts(normalize=True).unstack().fillna(0)\n",
    "P_k_given_fb_dd_wd_ft = train_data.groupby(['isFirstBlood', 'drakeDiff', 'wardsDiff', 'isFirstTower'])['kda'].value_counts(normalize=True).unstack().fillna(0)\n",
    "P_dd_given_wd = train_data.groupby('wardsDiff')['drakeDiff'].value_counts(normalize=True).unstack().fillna(0)\n",
    "P_fb_given_wd = train_data.groupby('wardsDiff')['isFirstBlood'].value_counts(normalize=True).unstack().fillna(0)\n",
    "P_ft_given_rh = train_data.groupby('killedRiftHerald')['isFirstTower'].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "# Compute marginal probabilities for nodes without parents\n",
    "P_wd = train_data['wardsDiff'].value_counts(normalize=True).to_dict()\n",
    "P_rh = train_data['killedRiftHerald'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "# DATA VISUALIZING\n",
    "display(P_hasWon_given_gd_ed_lp)\n",
    "display(P_lp_given_ft_rh)\n",
    "display(P_ed_given_k)\n",
    "display(P_k_given_fb_dd_wd_ft)\n",
    "display(P_dd_given_wd)\n",
    "display(P_fb_given_wd)\n",
    "display(P_ft_given_rh)\n",
    "display(P_wd)\n",
    "display(P_rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA TRAINING\n",
    "\n",
    "def predict_win_probability(evidence):\n",
    "    \"\"\"\n",
    "    Computes P(hasWon | evidence) using the trained Bayesian Network.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract evidence values\n",
    "        gd, ed, lp = evidence['goldDiff'], evidence['expDiff'], evidence['laneProgression']\n",
    "\n",
    "        # Compute probability of winning and losing\n",
    "        P_win = P_hasWon_given_gd_ed_lp.loc[gd, ed, lp].get(1, 1e-6)  # P(hasWon=1 | gd, ed, lp)\n",
    "        P_lose = P_hasWon_given_gd_ed_lp.loc[gd, ed, lp].get(0, 1e-6)  # P(hasWon=0 | gd, ed, lp)\n",
    "\n",
    "        # Normalize probabilities\n",
    "        total = P_win + P_lose\n",
    "        P_win /= total\n",
    "        P_lose /= total\n",
    "\n",
    "        return 1 if P_win > P_lose else 0  # Return predicted class\n",
    "    \n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key: {e}, using default probability\")\n",
    "        return np.random.choice([0, 1])  # Randomly assign if missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA TESTING AND EVALUATING\n",
    "\n",
    "# Testing data\n",
    "test_data['predicted_hasWon'] = test_data.apply(lambda row: predict_win_probability(row), axis=1)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = (test_data['hasWon'] == test_data['predicted_hasWon']).mean()\n",
    "print(f\"Model Accuracy: {accuracy*100:.2f}{'%'}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(test_data['hasWon'], test_data['predicted_hasWon'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Lose\", \"Win\"], yticklabels=[\"Lose\", \"Win\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed3372",
   "metadata": {},
   "source": [
    "HMM Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ba93b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 49.81%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define hidden states\n",
    "hidden_states = ['Disadvantaged', 'Even', 'Advantageous']\n",
    "n_states = len(hidden_states)\n",
    "\n",
    "# Create derived columns for full dataset (not just frame=10)\n",
    "df['kda'] = df['kills'] + (df['assists'] // 2) - df['deaths']\n",
    "df['wardsDiff'] = df['wardsPlaced'] - df['wardsLost']\n",
    "drake_columns_killed = ['killedFireDrake', 'killedWaterDrake', 'killedAirDrake', 'killedEarthDrake']\n",
    "drake_columns_lost = ['lostFireDrake', 'lostWaterDrake', 'lostAirDrake', 'lostEarthDrake']\n",
    "df['drakeDiff'] = df[drake_columns_killed].sum(axis=1) - df[drake_columns_lost].sum(axis=1)\n",
    "turrets_destroyed = ['destroyedTopOuterTurret', 'destroyedMidOuterTurret', 'destroyedBotOuterTurret']\n",
    "turret_lost = ['lostTopOuterTurret', 'lostMidOuterTurret', 'lostBotOuterTurret']\n",
    "df['laneProgression'] = df[turrets_destroyed].sum(axis=1) - df[turret_lost].sum(axis=1)\n",
    "\n",
    "# Discretize relevant columns\n",
    "df['goldDiff'] = (df['goldDiff'] > 0).astype(int)\n",
    "df['expDiff'] = (df['expDiff'] > 0).astype(int)\n",
    "df['wardsDiff'] = (df['wardsDiff'] > 0).astype(int)\n",
    "df['drakeDiff'] = (df['drakeDiff'] > 0).astype(int)\n",
    "df['kda'] = (df['kda'] > 1).astype(int)\n",
    "df['killedRiftHerald'] = (df['killedRiftHerald'] > 0).astype(int)\n",
    "df['laneProgression'] = (df['laneProgression'] > 0).astype(int)\n",
    "\n",
    "# Assign hidden states based on game advantage metrics\n",
    "states = np.full(len(df), 'Even', dtype=object)\n",
    "states[(df['goldDiff'] == 1) & (df['expDiff'] == 1)] = 'Advantageous'\n",
    "states[(df['goldDiff'] == 0) & (df['expDiff'] == 0)] = 'Disadvantaged'\n",
    "df['hidden_state'] = states\n",
    "\n",
    "assert set(df['hidden_state'].unique()).issubset(set(hidden_states)), \"Unexpected hidden state values found!\"\n",
    "\n",
    "##############################\n",
    "# 2. Compute Transition Probabilities\n",
    "##############################\n",
    "\n",
    "transition_matrix = np.zeros((n_states, n_states))\n",
    "state_map = {state: i for i, state in enumerate(hidden_states)}\n",
    "\n",
    "for prev, curr in zip(df['hidden_state'][:-1], df['hidden_state'][1:]):\n",
    "    transition_matrix[state_map[prev], state_map[curr]] += 1\n",
    "\n",
    "# Normalize transition matrix to ensure valid probabilities\n",
    "transition_matrix = (transition_matrix + 1e-6) / (transition_matrix.sum(axis=1, keepdims=True) + 1e-6)\n",
    "transition_matrix = np.log(transition_matrix)  # Convert to log-space to prevent underflow\n",
    "\n",
    "##############################\n",
    "# 3. Compute Emission Probabilities\n",
    "##############################\n",
    "\n",
    "observed_features = ['goldDiff', 'expDiff', 'kda', 'wardsDiff', \n",
    "                     'isFirstBlood', 'isFirstTower', 'killedRiftHerald', \n",
    "                     'drakeDiff', 'laneProgression']\n",
    "\n",
    "df_obs = df[observed_features].copy()\n",
    "emission_matrix = np.zeros((n_states, len(observed_features)))\n",
    "\n",
    "for state in hidden_states:\n",
    "    subset = df[df['hidden_state'] == state][observed_features]\n",
    "    if not subset.empty:\n",
    "        emission_matrix[state_map[state], :] = subset.mean().values\n",
    "\n",
    "# Convert to log-space\n",
    "emission_matrix = np.log(emission_matrix + 1e-6)\n",
    "\n",
    "##############################\n",
    "# 4. Forward-Backward Algorithm for Smoothing\n",
    "##############################\n",
    "\n",
    "def forward_backward(observations, transition_matrix, emission_matrix, start_probs):\n",
    "    T = len(observations)\n",
    "    alpha = np.zeros((T, n_states))\n",
    "    beta = np.zeros((T, n_states))\n",
    "    \n",
    "    # Forward pass\n",
    "    alpha[0, :] = np.log(start_probs) + np.sum(observations[0] * emission_matrix, axis=1)\n",
    "    for t in range(1, T):\n",
    "        for j in range(n_states):\n",
    "            alpha[t, j] = np.logaddexp.reduce(alpha[t-1] + transition_matrix[:, j]) + np.sum(observations[t] * emission_matrix[j])\n",
    "    \n",
    "    # Backward pass\n",
    "    beta[-1, :] = 0  # log(1) = 0\n",
    "    for t in range(T-2, -1, -1):\n",
    "        for j in range(n_states):\n",
    "            beta[t, j] = np.logaddexp.reduce(beta[t+1] + transition_matrix[j, :] + np.sum(observations[t+1] * emission_matrix, axis=1))\n",
    "    \n",
    "    # Compute smoothed probabilities\n",
    "    smoothed_probs = alpha + beta\n",
    "    smoothed_probs -= np.logaddexp.reduce(smoothed_probs, axis=1, keepdims=True)  # Normalize\n",
    "    \n",
    "    return smoothed_probs\n",
    "\n",
    "##############################\n",
    "# 5. Model Evaluation: Predicting Probability of Win\n",
    "##############################\n",
    "\n",
    "start_probs = np.ones(n_states) / n_states\n",
    "observations = df_obs.values\n",
    "smoothed_probs = forward_backward(observations, transition_matrix, emission_matrix, start_probs)\n",
    "\n",
    "df['predicted_hidden_state'] = [hidden_states[np.argmax(p)] for p in smoothed_probs]\n",
    "\n",
    "# Predict win based on most probable state at final time step\n",
    "df['predicted_hasWon'] = (df['predicted_hidden_state'] == 'Advantageous').astype(int)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(df['hasWon'], df['predicted_hasWon'])\n",
    "conf_matrix = confusion_matrix(df['hasWon'], df['predicted_hasWon'])\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Lose\", \"Win\"], yticklabels=[\"Lose\", \"Win\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd75872e",
   "metadata": {},
   "source": [
    "Other models for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cfc8d68d10e87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:39:30.892272Z",
     "start_time": "2025-03-16T04:38:26.701214Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "###################################\n",
    "#         Configuration           #\n",
    "###################################\n",
    "DATA_PATH = \"./data/lol_ranked_games.csv\"  # Adjust if needed\n",
    "TARGET_COL = \"hasWon\"  # Target column for classification\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 1337\n",
    "\n",
    "# Set seeds for reproducibility (PyTorch, numpy, python.random)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "# If you have other random libs, set them similarly.\n",
    "\n",
    "###################################\n",
    "#        1. Load & Split Data     #\n",
    "###################################\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Data shape:\", df.shape)\n",
    "\n",
    "print(\"\\n[Label Distribution]\")\n",
    "print(df[TARGET_COL].value_counts())\n",
    "print(\"\\n[Unique Labels]\")\n",
    "print(df[TARGET_COL].unique())\n",
    "\n",
    "# Ensure labels are 0 or 1. If not, map them.\n",
    "# Example if your dataset uses \"Blue\" / \"Red\" or 1 / 2:\n",
    "# df[TARGET_COL] = df[TARGET_COL].map({\"Blue\": 0, \"Red\": 1})\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "print(\"\\nData info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "missing_vals = df.isna().sum()\n",
    "print(\"\\nMissing values in each column:\\n\", missing_vals)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set size: {X_train.shape[0]} | Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Optional: check class distribution in training set\n",
    "print(\"\\nTraining set label distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "##################################\n",
    "#    2. Scale/Normalize Inputs   #\n",
    "##################################\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to torch tensors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "X_train_torch = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "y_train_torch = torch.tensor(y_train.values, dtype=torch.long).to(device)\n",
    "X_test_torch  = torch.tensor(X_test_scaled,  dtype=torch.float32).to(device)\n",
    "y_test_torch  = torch.tensor(y_test.values,  dtype=torch.long).to(device)\n",
    "\n",
    "##################################\n",
    "#  3. Define AdvancedNN Model    #\n",
    "##################################\n",
    "class AdvancedNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden1=128, hidden2=64, hidden3=32, output_dim=2, dropout_p=0.2):\n",
    "        super(AdvancedNN, self).__init__()\n",
    "        # Layer 1\n",
    "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden1)\n",
    "        self.dropout1 = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Layer 2\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden2)\n",
    "        self.dropout2 = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Layer 3\n",
    "        self.fc3 = nn.Linear(hidden2, hidden3)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden3)\n",
    "        self.dropout3 = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc4 = nn.Linear(hidden3, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "##############################\n",
    "# 4. Initialize & Train NN   #\n",
    "##############################\n",
    "model = AdvancedNN(input_dim=X_train_torch.shape[1], dropout_p=0.2).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)  # smaller LR\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "print(\"\\n[Training Advanced Neural Network]\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    permutation = torch.randperm(X_train_torch.size(0))\n",
    "\n",
    "    running_loss = 0.0\n",
    "    num_batches = int(np.ceil(X_train_torch.size(0) / batch_size))\n",
    "\n",
    "    batch_iter = tqdm(range(0, X_train_torch.size(0), batch_size),\n",
    "                      desc=f\"Epoch {epoch+1}/{epochs}\",\n",
    "                      leave=False)\n",
    "\n",
    "    for i in batch_iter:\n",
    "        indices = permutation[i : i + batch_size]\n",
    "        batch_x, batch_y = X_train_torch[indices], y_train_torch[indices]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Evaluate on test set each epoch\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_torch)\n",
    "        _, test_preds = torch.max(test_outputs, 1)\n",
    "        test_acc = (test_preds == y_test_torch).float().mean().item()\n",
    "\n",
    "    avg_loss = running_loss / num_batches\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "# Final NN Accuracy\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_outputs = model(X_test_torch)\n",
    "    _, final_preds = torch.max(final_outputs, 1)\n",
    "nn_acc = (final_preds == y_test_torch).float().mean().item()\n",
    "print(f\"[Advanced Neural Network] Final Test Accuracy: {nn_acc:.4f}\")\n",
    "\n",
    "##############################\n",
    "#  5. Sanity Check Overfit   #\n",
    "##############################\n",
    "# (Optional) Test if the network can overfit a small subset\n",
    "# If it can't get near 100% on the training subset, there's definitely something wrong.\n",
    "subset_size = 200  # or smaller if your data is huge\n",
    "X_small = X_train_torch[:subset_size]\n",
    "y_small = y_train_torch[:subset_size]\n",
    "\n",
    "tmp_model = AdvancedNN(input_dim=X_small.shape[1], dropout_p=0.0).to(device)\n",
    "tmp_optimizer = optim.Adam(tmp_model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(100):\n",
    "    tmp_model.train()\n",
    "    tmp_optimizer.zero_grad()\n",
    "    outputs = tmp_model(X_small)\n",
    "    loss = criterion(outputs, y_small)\n",
    "    loss.backward()\n",
    "    tmp_optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = tmp_model(X_small)\n",
    "        _, pred_classes = torch.max(preds, 1)\n",
    "        train_acc = (pred_classes == y_small).float().mean().item()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"[Overfit Check] Epoch {epoch+1}, Loss: {loss.item():.4f}, Acc: {train_acc:.4f}\")\n",
    "\n",
    "# If this \"overfit check\" doesn't reach 95%+ accuracy on a tiny subset,\n",
    "# there's likely a data or code bug.\n",
    "\n",
    "##############################\n",
    "#    6. Save the Model       #\n",
    "##############################\n",
    "torch.save(model.state_dict(), \"advanced_nn_checkpoint.pth\")\n",
    "print(f\"\\nFinal Test Accuracy (full) = {nn_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0cdcf73e9432f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:41:33.335546Z",
     "start_time": "2025-03-16T04:41:07.079157Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1) XGBoost for GPU\n",
    "import xgboost as xgb\n",
    "\n",
    "# 2) Random Forest (CPU-based from scikit-learn)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 3) PyTorch for Neural Network (GPU if available)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# For displaying progress bars\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "###################################\n",
    "#         Configuration           #\n",
    "###################################\n",
    "DATA_PATH = \"./data/lol_ranked_games.csv\"  # Adjust if needed\n",
    "TARGET_COL = \"hasWon\"  # Target column for classification\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 1337\n",
    "\n",
    "###################################\n",
    "#        1. Load & Split Data     #\n",
    "###################################\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {X_train.shape[0]} | Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "##########################################\n",
    "#  2.1 Train XGBoost on GPU w/ tqdm      #\n",
    "##########################################\n",
    "# We'll manually loop through boosting rounds to display a tqdm progress bar.\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest  = xgb.DMatrix(X_test,  label=y_test)\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"tree_method\": \"gpu_hist\",     # GPU usage\n",
    "    \"predictor\": \"gpu_predictor\",  # GPU usage\n",
    "    \"seed\": RANDOM_SEED\n",
    "}\n",
    "\n",
    "num_boost_round = 100\n",
    "booster = None\n",
    "\n",
    "print(\"\\n[Training XGBoost]\")\n",
    "for i in tqdm(range(num_boost_round), desc=\"XGBoost Rounds\"):\n",
    "    # Train 1 boosting round at a time, continuing on the existing booster\n",
    "    booster = xgb.train(\n",
    "        params=xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=1,\n",
    "        xgb_model=booster  # continue on previously trained model\n",
    "    )\n",
    "\n",
    "# Evaluate XGBoost\n",
    "xgb_pred_proba = booster.predict(dtest)\n",
    "xgb_pred = [1 if p > 0.5 else 0 for p in xgb_pred_proba]\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "print(f\"[XGBoost] Test Accuracy: {xgb_acc:.4f}\")\n",
    "\n",
    "# Save XGBoost model\n",
    "booster.save_model(\"xgboost_gpu.model\")\n",
    "\n",
    "##########################################\n",
    "#  2.2 Train RandomForest w/ tqdm (CPU)  #\n",
    "##########################################\n",
    "# scikit-learn RandomForest doesn't natively show progress. We'll do an incremental approach:\n",
    "trees = 100\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=1,      # start with 1 tree\n",
    "    warm_start=True,     # allow incremental training\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(\"\\n[Training Random Forest (CPU)]\")\n",
    "for i in tqdm(range(1, trees + 1), desc=\"RandomForest Trees\"):\n",
    "    rf.set_params(n_estimators=i)  # incrementally add trees\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "print(f\"[Random Forest] Test Accuracy: {rf_acc:.4f}\")\n",
    "\n",
    "# Save Random Forest model\n",
    "with open(\"random_forest.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf, f)\n",
    "\n",
    "\n",
    "##########################################\n",
    "#        3. Compare and Print Results    #\n",
    "##########################################\n",
    "print(\"\\n======================================\")\n",
    "print(\"Model Accuracy Comparison:\")\n",
    "print(f\" - XGBoost (GPU):          {xgb_acc:.4f}\")\n",
    "print(f\" - Random Forest (CPU):    {rf_acc:.4f}\")\n",
    "print(f\" - Neural Network (GPU?):  {nn_acc:.4f}\")\n",
    "print(\"======================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895534e0e4eb0b14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T19:59:18.917007Z",
     "start_time": "2025-03-16T19:59:05.193071Z"
    }
   },
   "outputs": [],
   "source": [
    "# PCA Implementation and Enhanced Neural Network\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "###################################\n",
    "#         Configuration           #\n",
    "###################################\n",
    "DATA_PATH = \"./data/lol_ranked_games.csv\"\n",
    "TARGET_COL = \"hasWon\"\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 1337\n",
    "PCA_COMPONENTS = 0.95  # Keep 95% of variance\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "###################################\n",
    "#    1. Load & Preprocess Data    #\n",
    "###################################\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "# df = df[df['frame'] == 30]\n",
    "# high_impact_columns = ['hasWon', 'goldDiff', 'expDiff', 'champLevelDiff', 'kills', 'deaths', 'assists', 'isFirstTower', 'isFirstBlood']\n",
    "# df = df[high_impact_columns]\n",
    "print(\"Data shape:\", df.shape)\n",
    "\n",
    "print(\"\\n[Label Distribution]\")\n",
    "print(df[TARGET_COL].value_counts())\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Check for missing values\n",
    "missing_vals = df.isna().sum()\n",
    "print(\"\\nMissing values in each column:\\n\", missing_vals)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set size: {X_train.shape[0]} | Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "###################################\n",
    "#    2. Apply PCA Reduction       #\n",
    "###################################\n",
    "# Scale data first\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=PCA_COMPONENTS, random_state=RANDOM_SEED)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Print PCA information\n",
    "print(f\"\\nOriginal feature count: {X_train.shape[1]}\")\n",
    "print(f\"PCA reduced feature count: {X_train_pca.shape[1]}\")\n",
    "print(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "\n",
    "# Visualize explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by Components')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Convert to torch tensors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "X_train_torch = torch.tensor(X_train_pca, dtype=torch.float32).to(device)\n",
    "y_train_torch = torch.tensor(y_train.values, dtype=torch.long).to(device)\n",
    "X_test_torch = torch.tensor(X_test_pca, dtype=torch.float32).to(device)\n",
    "y_test_torch = torch.tensor(y_test.values, dtype=torch.long).to(device)\n",
    "\n",
    "###################################\n",
    "#  3. Enhanced Neural Network     #\n",
    "###################################\n",
    "class EnhancedNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 128, 64], output_dim=2, dropout_p=0.3):\n",
    "        super(EnhancedNN, self).__init__()\n",
    "\n",
    "        # Create layers dynamically based on hidden_dims\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # Input layer\n",
    "        self.layers.append(nn.Linear(input_dim, hidden_dims[0]))\n",
    "        self.layers.append(nn.BatchNorm1d(hidden_dims[0]))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout_p))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            self.layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            self.layers.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout_p))\n",
    "\n",
    "        # Output layer\n",
    "        self.output = nn.Linear(hidden_dims[-1], output_dim)\n",
    "\n",
    "        # Residual connections (for layers with matching dimensions)\n",
    "        self.use_residual = len(hidden_dims) > 1\n",
    "        if self.use_residual:\n",
    "            self.residual_layers = nn.ModuleList()\n",
    "            for i in range(len(hidden_dims)-1):\n",
    "                if hidden_dims[i] == hidden_dims[i+1]:\n",
    "                    self.residual_layers.append(nn.Identity())\n",
    "                else:\n",
    "                    self.residual_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer_outputs = []\n",
    "\n",
    "        # Process through first layer\n",
    "        x = self.layers[0](x)  # Linear\n",
    "        x = self.layers[1](x)  # BatchNorm\n",
    "        x = self.layers[2](x)  # ReLU\n",
    "        x = self.layers[3](x)  # Dropout\n",
    "        layer_outputs.append(x)\n",
    "\n",
    "        # Process through hidden layers with residual connections\n",
    "        layer_idx = 4\n",
    "        res_idx = 0\n",
    "\n",
    "        while layer_idx < len(self.layers):\n",
    "            identity = layer_outputs[-1]\n",
    "\n",
    "            x = self.layers[layer_idx](x)     # Linear\n",
    "            x = self.layers[layer_idx+1](x)   # BatchNorm\n",
    "\n",
    "            # Add residual connection if dimensions match\n",
    "            if self.use_residual:\n",
    "                x = x + self.residual_layers[res_idx](identity)\n",
    "                res_idx += 1\n",
    "\n",
    "            x = self.layers[layer_idx+2](x)   # ReLU\n",
    "            x = self.layers[layer_idx+3](x)   # Dropout\n",
    "\n",
    "            layer_outputs.append(x)\n",
    "            layer_idx += 4\n",
    "\n",
    "        # Output layer\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "###################################\n",
    "#  4. Training with Improvements  #\n",
    "###################################\n",
    "# Initialize model with improved architecture\n",
    "model = EnhancedNN(\n",
    "    input_dim=X_train_torch.shape[1],\n",
    "    hidden_dims=[256, 128, 64, 32],  # Deeper network\n",
    "    dropout_p=0.3\n",
    ").to(device)\n",
    "\n",
    "# Use weighted loss for imbalanced classes if needed\n",
    "class_counts = y_train.value_counts()\n",
    "if abs(class_counts[0] - class_counts[1]) > 0.1 * len(y_train):\n",
    "    class_weights = torch.tensor([1.0, class_counts[0]/class_counts[1]], dtype=torch.float32).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    print(f\"Using weighted loss with weights: {class_weights.cpu().numpy()}\")\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate scheduler and optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# Training parameters\n",
    "epochs = 10\n",
    "batch_size = 250\n",
    "early_stopping_patience = 15\n",
    "best_val_loss = float('inf')\n",
    "no_improve_epochs = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "print(\"\\n[Training Enhanced Neural Network with PCA]\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    permutation = torch.randperm(X_train_torch.size(0))\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    num_batches = int(np.ceil(X_train_torch.size(0) / batch_size))\n",
    "\n",
    "    # Use tqdm for progress tracking\n",
    "    batch_iterator = tqdm(range(0, X_train_torch.size(0), batch_size),\n",
    "                          desc=f\"Epoch {epoch+1}/{epochs}\",\n",
    "                          leave=False,\n",
    "                          total=num_batches)\n",
    "\n",
    "    for i in batch_iterator:\n",
    "        # Get batch indices\n",
    "        indices = permutation[i:i+batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_x, batch_y = X_train_torch[indices], y_train_torch[indices]\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += batch_y.size(0)\n",
    "        correct_train += (predicted == batch_y).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        batch_iterator.set_postfix({\n",
    "            'loss': loss.item(),\n",
    "            'acc': correct_train / total_train\n",
    "        })\n",
    "\n",
    "    # Calculate training metrics\n",
    "    train_loss = running_loss / num_batches\n",
    "    train_acc = correct_train / total_train\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Process validation data in batches to avoid memory issues\n",
    "        for i in range(0, X_test_torch.size(0), batch_size):\n",
    "            batch_x = X_test_torch[i:i+batch_size]\n",
    "            batch_y = y_test_torch[i:i+batch_size]\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += batch_y.size(0)\n",
    "            correct_val += (predicted == batch_y).sum().item()\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_loss = val_loss / (X_test_torch.size(0) // batch_size + 1)\n",
    "    val_acc = correct_val / total_val\n",
    "\n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "          f\"Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Overfit check as requested\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"[Overfit Check] Epoch {epoch+1}, Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "        if train_acc - val_acc > 0.05:\n",
    "            print(f\"⚠️ Potential overfitting detected: Train acc {train_acc:.4f} vs Val acc {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Loaded best model based on validation loss\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'enhanced_nn_checkpoint.pth')\n",
    "print(\"Model saved to 'enhanced_nn_checkpoint.pth'\")\n",
    "\n",
    "###################################\n",
    "#  5. Evaluate Final Model        #\n",
    "###################################\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get predictions\n",
    "    y_pred = model(X_test_torch)\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    predicted = predicted.cpu().numpy()\n",
    "    y_true = y_test_torch.cpu().numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, predicted)\n",
    "    report = classification_report(y_true, predicted)\n",
    "    conf_matrix = confusion_matrix(y_true, predicted)\n",
    "\n",
    "    print(f\"\\n[Final Model Evaluation]\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Loss', 'Win'],\n",
    "                yticklabels=['Loss', 'Win'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "###################################\n",
    "#  6. Visualize Training History  #\n",
    "###################################\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "###################################\n",
    "#  7. Feature Importance Analysis #\n",
    "###################################\n",
    "# Get feature importance from PCA components\n",
    "feature_importance = np.abs(pca.components_).sum(axis=0)\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
    "plt.title('Top 15 Features by PCA Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(importance_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
